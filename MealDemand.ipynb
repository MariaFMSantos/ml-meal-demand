{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nPa9bJjFwwx5"
      },
      "source": [
        "#**Pré-Processamento**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SNLA7Xq92M3s"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow\n",
        "!pip install keras"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import xgboost as xgb\n",
        "import tensorflow\n",
        "\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "from matplotlib.lines import Line2D\n",
        "\n",
        "import random\n",
        "import os\n",
        "import re\n",
        "\n",
        "# Configuração visual dos gráficos\n",
        "plt.style.use(\"fivethirtyeight\")\n",
        "color_pal = sns.color_palette()\n",
        "\n",
        "# Fixar seed para reprodutibilidade\n",
        "def set_seed(seed=42):\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    tensorflow.random.set_seed(seed)\n",
        "\n",
        "set_seed(42)"
      ],
      "metadata": {
        "id": "ErwG442OUtzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Carrega o dataset.\n",
        "# O arquivo \"ToyDataset.xlsx\" deve estar dentro da pasta \"Data\"\n",
        "# no mesmo diretório do notebook.\n",
        "\n",
        "df = pd.read_excel(\n",
        "    \"Data/ToyDataset.xlsx\",\n",
        "    parse_dates=['DATA']\n",
        ")"
      ],
      "metadata": {
        "id": "O8vZ1FblVI9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJFTMLDHySxD"
      },
      "outputs": [],
      "source": [
        "intervalos_ferias = [\n",
        "    (pd.to_datetime('2023-01-01'), pd.to_datetime('2023-04-02')),  # Férias antes do primeiro período letivo de 2023\n",
        "    (pd.to_datetime('2023-07-23'), pd.to_datetime('2023-08-09')),  # Férias entre os períodos letivos de 2023\n",
        "    (pd.to_datetime('2023-12-24'), pd.to_datetime('2023-12-31')),  # Férias depois do segundo período letivo de 2023\n",
        "    (pd.to_datetime('2024-01-01'), pd.to_datetime('2024-03-17')),  # Férias antes do primeiro período letivo de 2024\n",
        "    (pd.to_datetime('2024-07-21'), pd.to_datetime('2024-08-11')),  # Férias entre os períodos letivos de 2024\n",
        "    (pd.to_datetime('2024-12-15'), pd.to_datetime('2024-12-31'))   # Férias depois do segundo período letivo de 2024\n",
        "]\n",
        "\n",
        "# Função para verificar se a data está no intervalo de férias\n",
        "def verificar_ferias(data, intervalos):\n",
        "    for inicio, fim in intervalos:\n",
        "        if inicio <= data <= fim:\n",
        "            return 1  # Férias\n",
        "    return 0  # Não é férias\n",
        "\n",
        "# Atualizar o DataFrame com a nova coluna \"Férias\"\n",
        "df['É_FÉRIAS'] = df['DATA'].apply(lambda x: verificar_ferias(x, intervalos_ferias))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lwDpki-Dytfn"
      },
      "outputs": [],
      "source": [
        "feriados = pd.to_datetime([\n",
        "    '2023-01-01',  # Ano Novo\n",
        "    '2023-02-20',  # Carnaval (Facultativo)\n",
        "    '2023-02-21',  # Carnaval (Facultativo)\n",
        "    '2023-02-22',  # Quarta-feira de Cinzas (Facultativo)\n",
        "    '2023-02-23',  # Recesso\n",
        "    '2023-02-24',  # Recesso\n",
        "    '2023-02-27',  # Recesso\n",
        "    '2023-02-28',  # Recesso\n",
        "    '2023-04-07',  # Sexta-Feira Santa\n",
        "    '2023-04-21',  # Tiradentes\n",
        "    '2023-04-23',  # São Jorge (Feriado Municipal)\n",
        "    '2023-05-01',  # Dia do Trabalho\n",
        "    '2023-06-08',  # Corpus Christi (Facultativo)\n",
        "    '2023-06-24',  # Feriado Municipal\n",
        "    '2023-07-29',  # Feriado Municipal\n",
        "    '2023-09-07',  # Independência do Brasil\n",
        "    '2023-10-12',  # Nossa Senhora Aparecida\n",
        "    '2023-10-15',  # Dia do Professor (Facultativo)\n",
        "    '2023-10-16',  # Dia do Comerciário (Feriado Municipal)\n",
        "    '2023-10-28',  # Dia do Servidor Público (Facultativo)\n",
        "    '2023-11-02',  # Dia de Finados\n",
        "    '2023-11-15',  # Proclamação da República\n",
        "    '2023-11-20',  # Dia da Consciência Negra (Feriado Estadual)\n",
        "    '2023-12-25',  # Natal\n",
        "    '2024-01-01',  # Ano Novo\n",
        "    '2024-02-12',  # Carnaval (Facultativo)\n",
        "    '2024-02-13',  # Carnaval (Facultativo)\n",
        "    '2024-02-14',  # Quarta-feira de Cinzas (Facultativo)\n",
        "    '2024-03-29',  # Sexta-Feira Santa\n",
        "    '2024-04-21',  # Tiradentes\n",
        "    '2024-04-23',  # São Jorge (Feriado Estadual)\n",
        "    '2024-05-01',  # Dia do Trabalhador\n",
        "    '2024-05-30',  # Corpus Christi (Facultativo)\n",
        "    '2024-06-24',  # Dia de São João Batista (Feriado Municipal)\n",
        "    '2024-07-29',  # Aniversário de Macaé (Feriado Municipal)\n",
        "    '2024-09-07',  # Independência do Brasil\n",
        "    '2024-10-12',  # Nossa Senhora Aparecida\n",
        "    '2024-10-28',  # Dia do Servidor Público (Facultativo)\n",
        "    '2024-11-02',  # Dia de Finados\n",
        "    '2024-11-15',  # Proclamação da República\n",
        "    '2024-11-20',  # Dia da Consciência Negra\n",
        "    '2024-12-25',  # Natal\n",
        "])\n",
        "\n",
        "df['FERIADO'] = df['DATA'].isin(feriados).astype(int)\n",
        "df['PRÉ_FERIADO'] = df['DATA'].isin(feriados - pd.Timedelta(days=1)).astype(int)\n",
        "df['PÓS_FERIADO'] = df['DATA'].isin(feriados + pd.Timedelta(days=1)).astype(int)\n",
        "\n",
        "df.loc[df['FERIADO'] == 1, 'POLO_QUANTIDADE'] = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P2WD7Hz42rtE"
      },
      "outputs": [],
      "source": [
        "def transformar_dados(df, usar_ciclico=True):\n",
        "    df = df.copy()\n",
        "\n",
        "    # Manter apenas dias úteis (segunda a sexta)\n",
        "    df = df.loc[df['DATA'].dt.weekday < 5]\n",
        "\n",
        "    # Features temporais básicas\n",
        "    df['DIA_SEMANA'] = df['DATA'].dt.weekday\n",
        "    df['MES'] = df['DATA'].dt.month\n",
        "\n",
        "    if usar_ciclico:\n",
        "        df['DIA_SEM_SIN'] = np.sin(2 * np.pi * df['DIA_SEMANA'] / 5)\n",
        "        df['DIA_SEM_COS'] = np.cos(2 * np.pi * df['DIA_SEMANA'] / 5)\n",
        "        df['MES_SIN'] = np.sin(2 * np.pi * df['MES'] / 12)\n",
        "        df['MES_COS'] = np.cos(2 * np.pi * df['MES'] / 12)\n",
        "\n",
        "        df.drop(columns=['DIA_SEMANA', 'MES'], inplace=True)\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TD4SrhuC3wFe"
      },
      "outputs": [],
      "source": [
        "# Ajuste conforme o experimento:\n",
        "# True: aplica encoding cíclico (sen/cos)\n",
        "# False: mantém DIA_SEMANA e MES como valores inteiros\n",
        "planilha = transformar_dados(df, usar_ciclico=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mGUYBzpnckfa"
      },
      "outputs": [],
      "source": [
        "def processar_pratos(planilha, usar_pratos=True):\n",
        "\n",
        "    # Registrar quais pratos originais foram convertidos em cada categoria\n",
        "    historico = {\n",
        "        'sem_serviço': [],\n",
        "        'prato_nao_informado': [],\n",
        "        'aves': [],\n",
        "        'aves_cremosas': [],\n",
        "        'bovino_ensopadas': [],\n",
        "        'bovino_cremosas': [],\n",
        "        'suino': [],\n",
        "        'peixe_fruto_do_mar': [],\n",
        "        'mistos': [],\n",
        "        'outros': [],\n",
        "        'desconhecido': []\n",
        "    }\n",
        "\n",
        "    if not usar_pratos:\n",
        "        # Remove colunas relacionadas ao cardápio quando não forem usadas no experimento\n",
        "        colunas_prato = [col for col in planilha.columns if 'PRATO_PRINCIPAL' in col or col.startswith('prato_')]\n",
        "        planilha = planilha.drop(columns=colunas_prato, errors='ignore')\n",
        "        return planilha, historico\n",
        "\n",
        "    # Manter coluna original temporariamente para histórico\n",
        "    planilha['PRATO_PRINCIPAL_ORIGINAL'] = planilha['PRATO_PRINCIPAL']\n",
        "\n",
        "    # Categorias e palavras-chave para classificação dos pratos\n",
        "    categorias = {\n",
        "        'sem_serviço': ['feriado', 'recesso', 'final do contrato', 'sem serviço'],\n",
        "        'prato_nao_informado': ['prato não informado'],\n",
        "        'peixe_fruto_do_mar': ['peixe', 'camarão', 'salmão', 'tilápia'],\n",
        "        'suino': ['lombo', 'suíno', 'mignon suíno', 'lombinho'],\n",
        "        'mistos': ['misto', 'churrasquinho misto', 'goulash misto', 'picadinho misto'],\n",
        "        'aves_cremosas': ['fricassê', 'fricasse', 'estrogonofe de frango', 'empadão de frango', 'lasanha de frango'],\n",
        "        'bovino_cremosas': ['estrogonofe de carne', 'lasanha à bolonhesa', 'lasanha bolonhesa', 'lasanha de carne'],\n",
        "        'aves': ['frango', 'sobrecoxa', 'galinha'],\n",
        "        'bovino_ensopadas': ['carne', 'picadinho de carne', 'almôndega', 'almodega', 'goulash', 'escalope de carne']\n",
        "    }\n",
        "    # Classificar prato em categorias usando palavras-chave\n",
        "    def classificar_prato(nome_prato):\n",
        "        original = nome_prato\n",
        "\n",
        "        if pd.isna(nome_prato):\n",
        "            historico['desconhecido'].append(original)\n",
        "            return 'desconhecido'\n",
        "\n",
        "        nome_prato_proc = nome_prato.lower().strip()\n",
        "\n",
        "        for categoria, palavras in categorias.items():\n",
        "            for palavra in palavras:\n",
        "                if re.search(rf'\\b{re.escape(palavra)}\\b', nome_prato_proc):\n",
        "                    historico[categoria].append(original)\n",
        "                    return categoria\n",
        "\n",
        "        historico['outros'].append(original)\n",
        "        return 'outros'\n",
        "\n",
        "    # Aplicar classificação\n",
        "    planilha['PRATO_PRINCIPAL'] = planilha['PRATO_PRINCIPAL'].astype(str).apply(classificar_prato)\n",
        "\n",
        "    # Visualização rápida da distribuição das categorias\n",
        "    tabela_final = planilha['PRATO_PRINCIPAL'].value_counts().reset_index()\n",
        "    tabela_final.columns = ['Categoria', 'Quantidade']\n",
        "    tabela_final.index = tabela_final.index + 1\n",
        "    display(tabela_final)\n",
        "\n",
        "    # One-hot encoding das categorias de prato\n",
        "    planilha_one_hot = pd.get_dummies(planilha['PRATO_PRINCIPAL'], prefix='prato').astype(int)\n",
        "    planilha = pd.concat([planilha, planilha_one_hot], axis=1)\n",
        "\n",
        "    # Remover colunas originais de prato antes da modelagem\n",
        "    planilha = planilha.drop(columns=['PRATO_PRINCIPAL', 'PRATO_PRINCIPAL_ORIGINAL'], errors='ignore')\n",
        "\n",
        "    return planilha, historico"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xN7KFqs4-Hs"
      },
      "outputs": [],
      "source": [
        "# Ajuste conforme o experimento:\n",
        "# usar_pratos=True: aplica categorização, one-hot encoding e remove coluna original\n",
        "# usar_pratos=False: remove coluna de pratos (sem usar cardápio na previsão)\n",
        "df, historico = processar_pratos(planilha, usar_pratos=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90SGjlZzDod1"
      },
      "outputs": [],
      "source": [
        "# Ajustes finais do dataframe para modelagem e visualização\n",
        "df = df.set_index('DATA')\n",
        "df = df.astype(np.float32)\n",
        "\n",
        "df['POLO_QUANTIDADE'].plot(style=\".\", figsize=(15,5), color=color_pal[0],\n",
        "                           title=\"Consumo Diário de Refeições\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Verificar valores zerados e NaN\n",
        "indices_zero = df[df['POLO_QUANTIDADE'] == 0].index\n",
        "print(indices_zero)\n",
        "\n",
        "nan_indices = df[df['POLO_QUANTIDADE'].isna()].index\n",
        "print(nan_indices)"
      ],
      "metadata": {
        "id": "xgkJL_MfgKvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Garantir consistência dos dados: substituir possíveis NaN por 0 (não encontrados no recorte atual)\n",
        "df['POLO_QUANTIDADE'] = df['POLO_QUANTIDADE'].fillna(0)"
      ],
      "metadata": {
        "id": "DOFEYg4_gLII"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['POLO_QUANTIDADE'].plot(\n",
        "    style=\".\",\n",
        "    figsize=(15,5),\n",
        "    color=color_pal[0],\n",
        "    title=\"Consumo Diário de Refeições\"\n",
        ")"
      ],
      "metadata": {
        "id": "fC3TYcqIgOR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBrJPC2w0pfp"
      },
      "source": [
        "##**Modelos Baseados em Árvores de Decisão**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df1 = df.copy()"
      ],
      "metadata": {
        "id": "t_-WYjANhXKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CI5NYgoREfjR"
      },
      "outputs": [],
      "source": [
        "# Número de dias passados a considerar para lag\n",
        "n_passado = 5\n",
        "\n",
        "# Criar colunas de lag com valores anteriores\n",
        "for i in range(1, n_passado + 1):\n",
        "    df1[f'POLO_QUANTIDADE_{i}'] = df1['POLO_QUANTIDADE'].shift(i)\n",
        "\n",
        "# Salvar datas removidas por causa do lag\n",
        "datas_removidas_lag = df1[df1.isna().any(axis=1)].index\n",
        "\n",
        "# Remover linhas com NaN geradas pelo lag\n",
        "df1 = df1.dropna()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6VQVAZD9GUi0"
      },
      "outputs": [],
      "source": [
        "# Proporção de treino\n",
        "proporcao_treino = 0.8\n",
        "\n",
        "# Calcular número de amostras para treino\n",
        "tamanho_treino = int(len(df1) * proporcao_treino)\n",
        "\n",
        "# Data que separa treino e teste\n",
        "data_corte_treino = df1.index[tamanho_treino]\n",
        "\n",
        "# Divisão temporal\n",
        "treino = df1[df1.index < data_corte_treino]\n",
        "teste = df1[df1.index >= data_corte_treino]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qKQmKO8tG_yh"
      },
      "outputs": [],
      "source": [
        "# Salvar as datas removidas do conjunto de teste\n",
        "datas_removidas_teste = teste.iloc[:n_passado].index\n",
        "\n",
        "#Remover os primeiros 5 dias do conjunto de teste\n",
        "teste = teste.iloc[n_passado:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vbnzHGMm1FQe"
      },
      "outputs": [],
      "source": [
        "df1.columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t5MMGo9q1IF4"
      },
      "outputs": [],
      "source": [
        "alvo = 'POLO_QUANTIDADE'\n",
        "\n",
        "# Seleciona todas as colunas, exceto o alvo\n",
        "features = [col for col in df1.columns if col != alvo]\n",
        "\n",
        "X = df1[features]\n",
        "y = df1[[alvo]]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Features selecionadas:\")\n",
        "print(features)"
      ],
      "metadata": {
        "id": "uGV3RYrGjB8B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JD3cNJ6X1Sla"
      },
      "outputs": [],
      "source": [
        "X_treino = treino[features]\n",
        "y_treino = treino[alvo]\n",
        "\n",
        "X_teste = teste[features]\n",
        "y_teste = teste[alvo]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**EXECUTE APENAS A CÉLULA DO ALGORITMO QUE DESEJA UTILIZAR**"
      ],
      "metadata": {
        "id": "vp0UbMiak_ta"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zhw1DjddQos7"
      },
      "outputs": [],
      "source": [
        "#VERSÃO ÁRVORE\n",
        "\n",
        "# Inicializa regressor\n",
        "regressor = DecisionTreeRegressor(random_state=42)\n",
        "\n",
        "# Grid de hiperparâmetros\n",
        "param_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 6, 7, 8, 10, 12],\n",
        "    \"min_samples_split\": [2, 5, 10, 15, 20],\n",
        "    \"min_samples_leaf\": [1, 2, 4, 6, 8],\n",
        "    \"max_features\": [None, \"sqrt\", \"log2\"],\n",
        "    \"criterion\": [\"squared_error\", \"absolute_error\"]\n",
        "}\n",
        "\n",
        "# Busca pelos melhores hiperparâmetros via cross-validation\n",
        "search = GridSearchCV(\n",
        "    regressor,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='neg_root_mean_squared_error'\n",
        ").fit(X_treino.to_numpy(), y_treino.to_numpy())\n",
        "\n",
        "print(\"Os melhores hiperparâmetros são \", search.best_params_)\n",
        "\n",
        "# Salva o melhor modelo para uso posterior\n",
        "reg = search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mxc9l8qMsIOS"
      },
      "outputs": [],
      "source": [
        "#Versão XGBOOST\n",
        "\n",
        "# Classe personalizada para evitar previsões negativas\n",
        "class XGBRegressorPositivo(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, **kwargs):\n",
        "        self.model = xgb.XGBRegressor(**kwargs)\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model.fit(X, y)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        preds = self.model.predict(X)\n",
        "        return np.maximum(preds, 0)  # Corrige valores negativos\n",
        "\n",
        "    def get_params(self, deep=True):\n",
        "        return self.model.get_params(deep)\n",
        "\n",
        "    def set_params(self, **params):\n",
        "        self.model.set_params(**params)\n",
        "        return self\n",
        "\n",
        "# Inicializa regressor XGBoost personalizado\n",
        "regressor = XGBRegressorPositivo(eval_metric='rmse', random_state=42)\n",
        "\n",
        "# Grid de hiperparâmetros\n",
        "param_grid = {\n",
        "    \"max_depth\": [3, 4, 5, 6, 7, 8],\n",
        "    \"n_estimators\": [300, 400, 500, 600, 700],\n",
        "    \"learning_rate\": [0.015, 0.020, 0.025, 0.05],\n",
        "    \"base_score\": [0.5],\n",
        "    \"booster\": ['gbtree'],\n",
        "    \"objective\": ['reg:squarederror'],\n",
        "}\n",
        "\n",
        "# Busca pelos melhores hiperparâmetros\n",
        "search = GridSearchCV(regressor, param_grid, cv=5).fit(X_treino.to_numpy(), y_treino.to_numpy())\n",
        "print(\"Os melhores hiperparâmetros são \", search.best_params_)\n",
        "\n",
        "# Salva o melhor modelo para uso posterior\n",
        "reg = search.best_estimator_"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "treino = treino.copy()\n",
        "teste = teste.copy()\n",
        "\n",
        "# Criar previsões usando .to_numpy() para evitar UserWarning de feature names\n",
        "treino[\"Previsão\"] = reg.predict(X_treino.to_numpy())\n",
        "teste[\"Previsão\"] = reg.predict(X_teste.to_numpy())\n",
        "\n",
        "# Criar o gráfico\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "\n",
        "# Definir fundo branco\n",
        "ax.set_facecolor('white')\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# Plotar valores reais e previsões\n",
        "treino[\"POLO_QUANTIDADE\"].plot(ax=ax, label=\"Treino - Real\", color='blue')\n",
        "treino[\"Previsão\"].plot(ax=ax, label=\"Treino - Prev.\", color='orange', linestyle='--')\n",
        "teste[\"POLO_QUANTIDADE\"].plot(ax=ax, label=\"Teste - Real\", color='skyblue')\n",
        "teste[\"Previsão\"].plot(ax=ax, label=\"Teste - Prev.\", color='red', linestyle='--')\n",
        "\n",
        "# Remover título e label do eixo X\n",
        "ax.set_title(\"\")\n",
        "ax.set_xlabel(\"\")\n",
        "\n",
        "# Posicionar legenda abaixo do gráfico\n",
        "ax.legend(loc='upper center', bbox_to_anchor=(0.5, -0.2), ncol=2)\n",
        "\n",
        "# Ajustar layout e exibir\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Dd7Vir_QgDxv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y3pxRxEiYaiC"
      },
      "outputs": [],
      "source": [
        "# Calcular métricas de treino e teste\n",
        "rmse_treino = np.sqrt(mean_squared_error(treino[\"POLO_QUANTIDADE\"], treino[\"Previsão\"]))\n",
        "r2_treino = r2_score(treino[\"POLO_QUANTIDADE\"], treino[\"Previsão\"])\n",
        "rmse_teste = np.sqrt(mean_squared_error(teste[\"POLO_QUANTIDADE\"], teste[\"Previsão\"]))\n",
        "r2_teste = r2_score(teste[\"POLO_QUANTIDADE\"], teste[\"Previsão\"])\n",
        "\n",
        "# Criar a tabela de métricas e formatar valores\n",
        "tabela_metricas = pd.DataFrame({\n",
        "    \"Conjunto\": [\"Treino\", \"Teste\"],\n",
        "    \"RMSE\": [rmse_treino, rmse_teste],\n",
        "    \"R²\": [r2_treino, r2_teste]\n",
        "})\n",
        "tabela_metricas[\"RMSE\"] = tabela_metricas[\"RMSE\"].apply(lambda x: f\"{x:.5f}\")\n",
        "tabela_metricas[\"R²\"] = tabela_metricas[\"R²\"].apply(lambda x: f\"{x:.5f}\")\n",
        "\n",
        "# Criar a figura da tabela e ajustar visual\n",
        "fig, ax = plt.subplots(figsize=(5, 1.8))\n",
        "ax.axis('off')  # Remover eixos\n",
        "tabela = ax.table(\n",
        "    cellText=tabela_metricas.values,\n",
        "    colLabels=tabela_metricas.columns,\n",
        "    cellLoc='center',\n",
        "    colColours=['#4682B4'] * len(tabela_metricas.columns),\n",
        "    loc='center'\n",
        ")\n",
        "tabela.auto_set_font_size(False)\n",
        "tabela.set_fontsize(10)\n",
        "tabela.auto_set_column_width([0, 1, 2])\n",
        "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)  # Ajustar layout"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSTwRMXf3-CL"
      },
      "source": [
        "##**Modelo LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar cópia do DataFrame para LSTM\n",
        "df2 = df.copy()\n",
        "df2.shape"
      ],
      "metadata": {
        "id": "R1OjQarCnhqc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EASFugl9MqhH"
      },
      "outputs": [],
      "source": [
        "# Dividir em treino (64%), validação (16%) e teste (20%)\n",
        "tamanho_treino = round(len(df2) * 0.64)\n",
        "tamanho_validacao = round(len(df2) * 0.16)\n",
        "\n",
        "df_para_treinamento = df2[:tamanho_treino]\n",
        "df_para_validacao = df2[tamanho_treino:tamanho_treino + tamanho_validacao]\n",
        "df_para_teste = df2[tamanho_treino + tamanho_validacao:]\n",
        "\n",
        "df_para_treinamento.shape, df_para_validacao.shape, df_para_teste.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "w4W4y4kc4J09"
      },
      "outputs": [],
      "source": [
        "# Definir coluna alvo do LSTM\n",
        "coluna_alvo_lstm = ['POLO_QUANTIDADE']\n",
        "\n",
        "colunas_para_escalonar = coluna_alvo_lstm\n",
        "colunas_nao_escalonadas = [col for col in df2.columns if col not in coluna_alvo_lstm]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o67SkxLmNPIU"
      },
      "outputs": [],
      "source": [
        "# Criar o escalonador\n",
        "escalador = MinMaxScaler(feature_range=(0, 1))\n",
        "\n",
        "# Aplicar escalonamento no conjunto de treino\n",
        "df_para_treinamento_scaled = df_para_treinamento.copy()\n",
        "df_para_treinamento_scaled[colunas_para_escalonar] = escalador.fit_transform(\n",
        "    df_para_treinamento[colunas_para_escalonar]\n",
        ")\n",
        "\n",
        "# Aplicar escalonamento no conjunto de validação\n",
        "df_para_validacao_scaled = df_para_validacao.copy()\n",
        "df_para_validacao_scaled[colunas_para_escalonar] = escalador.transform(\n",
        "    df_para_validacao[colunas_para_escalonar]\n",
        ")\n",
        "\n",
        "# Aplicar escalonamento no conjunto de teste\n",
        "df_para_teste_scaled = df_para_teste.copy()\n",
        "df_para_teste_scaled[colunas_para_escalonar] = escalador.transform(\n",
        "    df_para_teste[colunas_para_escalonar]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Concatenar colunas escalonadas e não escalonadas\n",
        "df_para_treinamento_final = pd.concat(\n",
        "    [df_para_treinamento_scaled[colunas_para_escalonar], df_para_treinamento[colunas_nao_escalonadas]],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df_para_validacao_final = pd.concat(\n",
        "    [df_para_validacao_scaled[colunas_para_escalonar], df_para_validacao[colunas_nao_escalonadas]],\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df_para_teste_final = pd.concat(\n",
        "    [df_para_teste_scaled[colunas_para_escalonar], df_para_teste[colunas_nao_escalonadas]],\n",
        "    axis=1\n",
        ")"
      ],
      "metadata": {
        "id": "Dd00tj9_pkP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dX1zPLtkNZOR"
      },
      "outputs": [],
      "source": [
        "def criar_XY(conjunto_dados, n_passado):\n",
        "    conjunto_dados = conjunto_dados.values  # Converter para array NumPy\n",
        "    entradas_X = []  # Armazenar entradas\n",
        "    saidas_Y = []    # Armazenar saídas (alvo)\n",
        "\n",
        "    for i in range(n_passado, len(conjunto_dados)):\n",
        "        entradas_X.append(conjunto_dados[i - n_passado:i, :])  # Selecionar todas as colunas\n",
        "        saidas_Y.append(conjunto_dados[i, 0])  # O alvo é a primeira coluna (POLO_QUANTIDADE)\n",
        "\n",
        "    return np.array(entradas_X), np.array(saidas_Y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJV3c5aI4mQy"
      },
      "outputs": [],
      "source": [
        "# Definir número de dias passados a considerar\n",
        "n_passado = 5\n",
        "\n",
        "# Criar os conjuntos X e Y\n",
        "treino_X, treino_Y = criar_XY(df_para_treinamento_final, n_passado)\n",
        "validacao_X, validacao_Y = criar_XY(df_para_validacao_final, n_passado)\n",
        "teste_X, teste_Y = criar_XY(df_para_teste_final, n_passado)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "eWFKjaANZycV"
      },
      "outputs": [],
      "source": [
        "# Treinar e avaliar LSTM\n",
        "def treinar_e_avaliar_modelo(learning_rate, units, batch_size, epochs):\n",
        "    adam = optimizers.Adam(learning_rate=learning_rate)\n",
        "\n",
        "    # Definir modelo LSTM\n",
        "    model_lstm = Sequential()\n",
        "\n",
        "    # Escolher a arquitetura:\n",
        "    # 1 camada LSTM + Dense (ativa por padrão)\n",
        "    model_lstm.add(LSTM(units, activation='relu', input_shape=(treino_X.shape[1], treino_X.shape[2])))\n",
        "\n",
        "    # 2 camadas LSTM + Dense (descomentar para testar)\n",
        "    # model_lstm.add(LSTM(units, activation='relu', input_shape=(treino_X.shape[1], treino_X.shape[2]), return_sequences=True))\n",
        "    # model_lstm.add(LSTM(units, activation='relu'))\n",
        "\n",
        "    model_lstm.add(Dense(1, activation='relu'))\n",
        "    model_lstm.compile(loss='mse', optimizer=adam)\n",
        "\n",
        "    # Definir EarlyStopping\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "\n",
        "    # Treinar modelo\n",
        "    model_lstm.fit(\n",
        "        treino_X, treino_Y,\n",
        "        validation_data=(validacao_X, validacao_Y),\n",
        "        epochs=epochs, batch_size=batch_size, verbose=2,\n",
        "        callbacks=[early_stopping]\n",
        "    )\n",
        "\n",
        "    # Avaliar no conjunto de validação\n",
        "    predicoes_validacao = model_lstm.predict(validacao_X)\n",
        "\n",
        "    # Reverter escalonamento\n",
        "    predicoes_unscaled = escalador.inverse_transform(predicoes_validacao.reshape(-1, 1))\n",
        "    validacao_Y_unscaled = escalador.inverse_transform(validacao_Y.reshape(-1, 1))\n",
        "\n",
        "    # Calcular RMSE\n",
        "    rmse = np.sqrt(mean_squared_error(validacao_Y_unscaled, predicoes_unscaled))\n",
        "\n",
        "    print(f'Parâmetros: learning_rate={learning_rate}, units={units}, batch_size={batch_size}')\n",
        "    print(f'RMSE (Validação): {rmse}')\n",
        "\n",
        "    return model_lstm, rmse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = []\n",
        "\n",
        "# Hiperparâmetros a testar\n",
        "learning_rates = [0.005, 0.01, 0.025, 0.05]\n",
        "units_list = [5, 10, 20, 25]\n",
        "batch_sizes = [4, 8, 16]\n",
        "\n",
        "best_rmse = float('inf')\n",
        "best_model = None\n",
        "\n",
        "# Loop de experimentos\n",
        "for lr in learning_rates:\n",
        "    for units in units_list:\n",
        "        for batch in batch_sizes:\n",
        "            set_seed(42)\n",
        "            modelo, rmse = treinar_e_avaliar_modelo(lr, units, batch, epochs=500)\n",
        "\n",
        "            resultados.append({\n",
        "                'learning_rate': lr,\n",
        "                'units': units,\n",
        "                'batch_size': batch,\n",
        "                'rmse': rmse\n",
        "            })\n",
        "\n",
        "            # Atualizar melhor modelo\n",
        "            if rmse < best_rmse:\n",
        "                best_rmse = rmse\n",
        "                best_model = modelo\n",
        "\n",
        "print(f'\\nMelhor modelo encontrado com RMSE: {best_rmse}')"
      ],
      "metadata": {
        "id": "1u_ALwfIqeWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpqMvMnerJ9e"
      },
      "outputs": [],
      "source": [
        "# Criar função para fazer previsões e calcular métricas\n",
        "def fazer_previsoes_e_calcular_metricas(modelo, X, Y, escalador, indice_ajustado, n_passado):\n",
        "    # Fazer previsões\n",
        "    previsao = modelo.predict(X)\n",
        "    previsao_unscaled = escalador.inverse_transform(previsao.reshape(-1, 1))\n",
        "    Y_unscaled = escalador.inverse_transform(Y.reshape(-1, 1))\n",
        "\n",
        "    # Calcular métricas\n",
        "    rmse = np.sqrt(mean_squared_error(Y_unscaled, previsao_unscaled))\n",
        "    r2 = r2_score(Y_unscaled, previsao_unscaled)\n",
        "\n",
        "    # Ajustar índice considerando janela\n",
        "    indice_ajustado = indice_ajustado[n_passado:]\n",
        "\n",
        "    return previsao_unscaled, Y_unscaled, rmse, r2, indice_ajustado"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir janela de tempo\n",
        "n_passado = 5\n",
        "\n",
        "# Treino\n",
        "treino_pred, treino_real, rmse_treino, r2_treino, indice_treino_ajustado = fazer_previsoes_e_calcular_metricas(\n",
        "    best_model, treino_X, treino_Y, escalador, df_para_treinamento_final.index, n_passado\n",
        ")\n",
        "\n",
        "# Validação\n",
        "validacao_pred, validacao_real, rmse_validacao, r2_validacao, indice_validacao_ajustado = fazer_previsoes_e_calcular_metricas(\n",
        "    best_model, validacao_X, validacao_Y, escalador, df_para_validacao_final.index, n_passado\n",
        ")\n",
        "\n",
        "# Teste\n",
        "teste_pred, teste_real, rmse_teste, r2_teste, indice_teste_ajustado = fazer_previsoes_e_calcular_metricas(\n",
        "    best_model, teste_X, teste_Y, escalador, df_para_teste_final.index, n_passado\n",
        ")"
      ],
      "metadata": {
        "id": "z-mwFiiuq0rB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Criar tabela de métricas\n",
        "tabela_metricas = pd.DataFrame({\n",
        "    \"Conjunto\": [\"Treino\", \"Validação\", \"Teste\"],\n",
        "    \"RMSE\": [rmse_treino, rmse_validacao, rmse_teste],\n",
        "    \"R²\": [r2_treino, r2_validacao, r2_teste]\n",
        "})\n",
        "\n",
        "# Formatar valores com 2 casas decimais\n",
        "tabela_metricas[\"RMSE\"] = tabela_metricas[\"RMSE\"].apply(lambda x: f\"{x:.5f}\")\n",
        "tabela_metricas[\"R²\"] = tabela_metricas[\"R²\"].apply(lambda x: f\"{x:.5f}\")\n",
        "\n",
        "# Criar figura e tabela\n",
        "fig, ax = plt.subplots(figsize=(5, 2))\n",
        "ax.axis('off')\n",
        "tabela = ax.table(cellText=tabela_metricas.values,\n",
        "                  colLabels=tabela_metricas.columns,\n",
        "                  cellLoc='center',\n",
        "                  colColours=['#4682B4'] * len(tabela_metricas.columns),\n",
        "                  loc='center')\n",
        "\n",
        "# Ajustar tamanho da fonte e colunas\n",
        "tabela.auto_set_font_size(False)\n",
        "tabela.set_fontsize(10)\n",
        "tabela.auto_set_column_width([0, 1, 2])\n",
        "\n",
        "# Ajustar layout da figura\n",
        "plt.subplots_adjust(left=0.05, right=0.95, top=0.95, bottom=0.05)\n",
        "\n",
        "# Exibir tabela\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8Sq2SYeBq4a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfIO0z2XEJ3s"
      },
      "outputs": [],
      "source": [
        "# Criar figura e eixo\n",
        "fig, ax = plt.subplots(figsize=(15, 5))\n",
        "ax.set_facecolor('white')\n",
        "fig.patch.set_facecolor('white')\n",
        "\n",
        "# Plotar valores reais\n",
        "ax.plot(indice_treino_ajustado, treino_real, color='blue', linestyle='-')\n",
        "ax.plot(indice_validacao_ajustado, validacao_real, color='skyblue', linestyle='-')\n",
        "ax.plot(indice_teste_ajustado, teste_real, color='green', linestyle='-')\n",
        "\n",
        "# Plotar previsões\n",
        "ax.plot(indice_treino_ajustado, treino_pred, color='orange', linestyle='--')\n",
        "ax.plot(indice_validacao_ajustado, validacao_pred, color='red', linestyle='--')\n",
        "ax.plot(indice_teste_ajustado, teste_pred, color='purple', linestyle='--')\n",
        "\n",
        "# Remover título e label do eixo X\n",
        "ax.set_title(\"\")\n",
        "ax.set_xlabel(\"\")\n",
        "\n",
        "# Criar legenda personalizada\n",
        "legendas_personalizadas = [\n",
        "    Line2D([0], [0], color='blue', linestyle='-', label='Treino - Valor Real'),\n",
        "    Line2D([0], [0], color='orange', linestyle='--', label='Treino - Previsão'),\n",
        "    Line2D([0], [0], color='skyblue', linestyle='-', label='Validação - Valor Real'),\n",
        "    Line2D([0], [0], color='red', linestyle='--', label='Validação - Previsão'),\n",
        "    Line2D([0], [0], color='green', linestyle='-', label='Teste - Valor Real'),\n",
        "    Line2D([0], [0], color='purple', linestyle='--', label='Teste - Previsão'),\n",
        "]\n",
        "\n",
        "# Posicionar legenda em 3 colunas abaixo do gráfico\n",
        "ax.legend(handles=legendas_personalizadas, loc='upper center', bbox_to_anchor=(0.5, -0.35),\n",
        "          ncol=3, frameon=False)\n",
        "\n",
        "# Ajustar layout e exibir gráfico\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "LSTwRMXf3-CL"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}